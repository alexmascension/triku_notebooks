{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40b4c31-f808-4e45-a875-39ce2ea24640",
   "metadata": {},
   "source": [
    "# Additional comparisons\n",
    "\n",
    "In this notebook we will adapt secondary comparisons included during the review phase of the paper. Some of these comparisons may not appear on the paper, but are used to answer reviewers' questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41235e96-f421-4d4d-af76-7a260e890ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import scanpy as sc\n",
    "import triku as tk\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120b910-f67c-49bb-869d-335a1e66d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8430a6a-73d2-425f-bff0-715f7a464c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from triku_nb_code.comparing_feat_sel import plot_CV_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e6bb5-2333-4f1b-a32f-e2a6c3923528",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_methods_all = ['triku', 'm3drop', 'nbumi', 'scanpy', 'seurat', 'sct', 'scry', 'std', 'brennecke', 'all', 'random']\n",
    "\n",
    "palette = [\n",
    "        '#e91e63',  # triku\n",
    "        '#81c784',  # m3drop\n",
    "        '#388e3c',  # nbumi\n",
    "        '#90caf9',  # scanpy\n",
    "        '#2196f3',  # seurat\n",
    "        '#1565c0',  # sctransform\n",
    "        '#ff9800',  # std\n",
    "        '#ff5722',  # scry\n",
    "        '#ffca28',  # brennecke\n",
    "        '#A5B1C2',  # all\n",
    "        '#4B6584',  # random\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af40f79-9d4e-4e65-a9ab-ed8c3657e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mereu_dir = os.getcwd() + '/data/Mereu_2020/'\n",
    "ding_dir = os.getcwd() + '/data/Ding_2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40f54b-bb10-48c8-92a8-412a1a61aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized number of features to select per dataset\n",
    "ding_n_feat = dict(pd.read_csv(os.getcwd() + '/data/Ding_n_genes.csv', sep=',', index_col=0)['n_features'])\n",
    "mereu_n_feat = dict(pd.read_csv(os.getcwd() + '/data/Mereu_n_genes.csv', sep=',', index_col=0)['n_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de6f64-7cbb-4549-bbce-113d5840699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(adatax): \n",
    "    sc.pp.filter_cells(adatax, min_genes=100)\n",
    "    sc.pp.filter_genes(adatax, min_cells=3)\n",
    "    sc.pp.normalize_total(adatax, target_sum=1e4)\n",
    "    sc.pp.log1p(adatax)\n",
    "    return adatax\n",
    "\n",
    "def PCA_knn(adatax, seed):\n",
    "    try:\n",
    "        pca = PCA(n_components=30, whiten=True, svd_solver=\"auto\", random_state=seed,).fit_transform(adatax.X.toarray())\n",
    "    except: # the array is already dense\n",
    "        pca = PCA(n_components=30, whiten=True, svd_solver=\"auto\", random_state=seed,).fit_transform(adatax.X)\n",
    "\n",
    "    adatax.obsm['X_pca'] = pca\n",
    "    sc.pp.neighbors(adatax, random_state=seed, metric='cosine', n_neighbors=int(len(adatax) ** 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75fbed-4870-4c36-8b36-0dbdd6c20ced",
   "metadata": {},
   "source": [
    "## Train a classifier on labeled data with different FS methods and study accuracy\n",
    "\n",
    "* Get dataset (for instance, Ding 2020: 10X human)\n",
    "* Use different FS methods on that dataset to obtain one matrix each time\n",
    "* Train classifier on each differently feature-selected dataset\n",
    "* Compute accuracy (10def preprocessing(adata): \n",
    "    sc.pp.filter_cells(adata, min_genes=100)\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    return adata-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca5962-093b-40ee-8640-3a1aaa8dcfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(adata_whole, ranking, model, n_features, n_folds, seed=0):\n",
    "    fs_methods = ranking.columns.tolist() + ['all', 'random']\n",
    "    cv_scores = pd.DataFrame(index=np.arange(n_folds), columns=fs_methods)\n",
    "    for fs in fs_methods:\n",
    "        if fs == 'all':\n",
    "            selected_features = ranking.index.tolist()\n",
    "        elif fs == 'random':\n",
    "            idxs = np.random.choice(np.arange(len(ranking)), n_features, replace=False)\n",
    "            selected_features = ranking.index[idxs].tolist()\n",
    "        else:\n",
    "            selected_features = ranking.sort_values(by=fs)[fs][0:n_features].index.tolist()\n",
    "            \n",
    "        adata_sel = adata_whole[:, [var for var in adata_whole.var_names if var in selected_features]]\n",
    "        \n",
    "        PCA_knn(adata, seed)\n",
    "        \n",
    "        ###### SELECT MODEL ######\n",
    "        X = adata_sel.obsm['X_pca']\n",
    "        y = adata_sel.obs['cell_types']\n",
    "        \n",
    "        ###### SELECT MODEL ######\n",
    "        if model == 'decision_tree':\n",
    "            clf= DecisionTreeClassifier(class_weight='balanced', random_state=seed)\n",
    "        elif model == 'knn':\n",
    "            clf = KNeighborsClassifier(n_neighbors=10, n_jobs=8)\n",
    "        elif model == 'svc':\n",
    "            clf = SVC(class_weight='balanced', random_state=seed)\n",
    "        ###### COMPUTE CROSS-VALIDATION SCORE ######\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        scores = cross_val_score(clf, X, y, cv=skf, scoring='accuracy')\n",
    "        cv_scores.loc[:, fs] = scores\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a130b6-c92b-4f27-8a25-4fcab20a1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "ding_datasets = [fname.split('.')[0] for fname in os.listdir(ding_dir) if fname.endswith('h5ad')]\n",
    "mereu_datasets = [fname.split('.')[0] for fname in os.listdir(mereu_dir)  if fname.endswith('h5ad') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8518df9e-5c94-4735-be40-ea1e3c009e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models \n",
    "models = ['decision_tree', 'svc', 'knn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770cc188-4e46-4fbe-8a7e-ecd15f56204d",
   "metadata": {},
   "source": [
    "### Mereu datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc107d4-d6b8-4f27-8f39-1cbe6adf987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "os.makedirs(f'{os.getcwd()}/exports/effect_FS_on_classifiers/fixed_n_features/mereu/', exist_ok=True)\n",
    "\n",
    "for dset in mereu_datasets: \n",
    "    print(dset)\n",
    "    adata = sc.read(f'{mereu_dir}/{dset}.h5ad')\n",
    "    n_feat = int(mereu_n_feat[dset])\n",
    "    adata = preprocessing(adata)\n",
    "    if 'CellType' in adata.obs.columns:\n",
    "        adata.obs['cell_types'] = adata.obs['CellType']\n",
    "    ranking = pd.read_csv(f'{os.getcwd()}/exports/comparisons/mereu_{dset}-log_feature_ranks.csv', index_col=0)\n",
    "    for model in models:\n",
    "        cv_scores = cross_validation(adata, ranking, model, n_features=n_feat, n_folds=n_folds)\n",
    "        cv_scores.to_csv(f'{os.getcwd()}/exports/effect_FS_on_classifiers/fixed_n_features/mereu/CV_scores_{dset}_{model}_{n_feat}_{n_folds}-fold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3bde2-7601-4b58-ab67-ead57fa3c0c2",
   "metadata": {},
   "source": [
    "### Ding datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a624c-db16-496c-b61b-86a0aa002722",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "os.makedirs(f'{os.getcwd()}/exports/effect_FS_on_classifiers/fixed_n_features/ding/', exist_ok=True)\n",
    "for dset in ding_datasets: \n",
    "    print(dset) \n",
    "    adata = sc.read(f'{ding_dir}/{dset}.h5ad')\n",
    "    n_feat = int(ding_n_feat[dset])\n",
    "    adata = preprocessing(adata)\n",
    "    if 'CellType' in adata.obs.columns:\n",
    "        adata.obs['cell_types'] = adata.obs['CellType']\n",
    "    ranking = pd.read_csv(f'{os.getcwd()}/exports/comparisons/ding_{dset}-log_feature_ranks.csv', index_col=0)\n",
    "    for model in models:\n",
    "        cv_scores = cross_validation(adata, ranking, model, n_features=n_feat, n_folds=n_folds)\n",
    "        cv_scores.to_csv(f'{os.getcwd()}/exports/effect_FS_on_classifiers/fixed_n_features/ding/CV_scores_{dset}_{model}_{n_feat}_{n_folds}-fold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cbf190-0b62-4ebd-bc2d-d30822a134a2",
   "metadata": {},
   "source": [
    "#### Figure 4C and 5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae9c6b-c2ab-46ac-82c3-77f845abc3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in ['ding', 'mereu']:\n",
    "    plot_CV_scores(lab=lab, org='', CV_method='decision_tree', FS_methods=list_methods_all, palette=palette, sort_values='descending', \n",
    "                       read_dir=f'{os.getcwd()}/exports/effect_FS_on_classifiers/fixed_n_features/{lab}',\n",
    "                       filename=f\"decision_tree_{lab}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47062a-eda1-4d87-bddb-25393380099d",
   "metadata": {},
   "source": [
    "#### Figure S2C and S3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14b5bf-b21a-4e05-8eca-5199e83aad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in ['ding', 'mereu']:\n",
    "    plot_CV_scores(lab=lab, org='', CV_method='knn', FS_methods=list_methods_all, palette=palette, sort_values='descending', \n",
    "                       read_dir=f'{os.getcwd()}/exports/effect_FS_on_classifiers/fixed_n_features/{lab}',\n",
    "                       filename=f\"knn_{lab}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76450c-4494-4de0-a084-4109b4d36bd8",
   "metadata": {},
   "source": [
    "## DEG analysis\n",
    "\n",
    "In this section, we are going to analyze the ability to select DEGs from more informative populations in biological datasets. This would be a complement to the use of ARI in biological datasets. The approach will be the following:\n",
    "* Control: populations are the manually curated populations.\n",
    "* FS + all + random: create the specific adata with those selected features and run leiden to match the number of populations manually labelled.\n",
    "* Run DEGs in all cases with alpha = 0.01. \n",
    "* Extract relevant information from that analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8606bdc-505c-4bce-bbe0-5e54bfcda50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{os.getcwd()}/exports/DEGs_UMAP_leiden', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cae6ed-c833-4bc4-bc6a-b6a0bca6c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def extract_DEGs_UMAP_leiden_adata(lab, org, method, seed=0):\n",
    "    try:\n",
    "        adata = sc.read(f'{os.getcwd()}/data/{lab.capitalize()}_2020/{method}_{org}.h5ad')\n",
    "    except:\n",
    "        return 0\n",
    "    df_ranks = pd.read_csv(f'{os.getcwd()}/exports/comparisons/{lab}_{method}_{org}-log_feature_ranks.csv', index_col=0)\n",
    "    \n",
    "    if lab == 'ding':\n",
    "        n_HVG = ding_n_feat[f'{method}_{org}']\n",
    "    elif lab == 'mereu':\n",
    "        n_HVG = mereu_n_feat[f'{method}_{org}']\n",
    "    \n",
    "    preprocessing(adata)\n",
    "    try:\n",
    "        if 'CellType' in adata.obs.columns:\n",
    "            adata.obs['cell_types'] = adata.obs['CellType']\n",
    "\n",
    "        n_cell_types = len(set(adata.obs['cell_types']))\n",
    "        df_populations = pd.DataFrame(columns=['cell_types'] + list_methods_all, index=adata.obs_names)\n",
    "        df_populations['cell_types'] = adata.obs['cell_types'].cat.codes\n",
    "    except KeyError:\n",
    "        raise f\"ERROR IN {lab}, {org}, {method}, {seed}\"\n",
    "        \n",
    "    for FS_method in list_methods_all:\n",
    "        if FS_method == 'all':\n",
    "            selected_features = df_ranks.index.tolist()\n",
    "        elif FS_method == 'random':\n",
    "            idxs = np.random.choice(np.arange(len(adata.var_names)), n_HVG, replace=False)\n",
    "            selected_features = df_ranks.index[idxs].tolist()\n",
    "        else:\n",
    "            selected_features = df_ranks.sort_values(by=FS_method)[FS_method][0:n_HVG].index.tolist()\n",
    "    \n",
    "        adata_sub = adata.copy()[:, [i in selected_features for i in adata.var_names]]   \n",
    "        PCA_knn(adata_sub, seed)\n",
    "        \n",
    "        sc.tl.umap(adata_sub, random_state=seed)\n",
    "        X_UMAP_FS = adata_sub.obsm['X_umap']\n",
    "        np.savetxt(f'{os.getcwd()}/exports/DEGs_UMAP_leiden/UMAP_{lab}_{method}_{org}_FSmethod-{FS_method}_seed-{seed}.txt', \n",
    "                   X_UMAP_FS, fmt='%.4f')\n",
    "        \n",
    "        # Clustering binary search \n",
    "        depth = 0\n",
    "        min_res, max_res, max_depth = 0.1, 2, 7\n",
    "        while depth < max_depth:\n",
    "            if depth == 0:\n",
    "                sc.tl.leiden(adata_sub, resolution=min_res, random_state=seed)\n",
    "                leiden_sol, res_sol = adata_sub.obs[\"leiden\"], min_res\n",
    "                if len(list(dict.fromkeys(leiden_sol))) == n_cell_types:\n",
    "                    break\n",
    "\n",
    "                sc.tl.leiden(adata_sub, resolution=max_res, random_state=seed)\n",
    "                leiden_sol, res_sol = adata_sub.obs[\"leiden\"], max_res\n",
    "                if len(list(dict.fromkeys(leiden_sol))) == n_cell_types:\n",
    "                    break\n",
    "\n",
    "            mid_res = 0.5 * (max_res + min_res)\n",
    "            sc.tl.leiden(adata_sub, resolution=mid_res, random_state=seed)\n",
    "            leiden_sol, res_sol = adata_sub.obs[\"leiden\"], mid_res\n",
    "            n_clust_mid = len(list(dict.fromkeys(leiden_sol)))\n",
    "            if n_clust_mid == n_cell_types:\n",
    "                break\n",
    "\n",
    "            if n_clust_mid > n_cell_types:\n",
    "                max_res = mid_res\n",
    "            else:\n",
    "                min_res = mid_res\n",
    "\n",
    "            depth += 1\n",
    "\n",
    "        df_populations[FS_method] = adata_sub.obs[\"leiden\"].copy()\n",
    "        sc.tl.rank_genes_groups(adata_sub, groupby=f\"leiden\", method='wilcoxon')\n",
    "        \n",
    "        for var_DEGs in ['names', 'pvals_adj', 'scores']:\n",
    "            pd.DataFrame(adata_sub.uns['rank_genes_groups'][var_DEGs]).to_csv(\n",
    "                f'{os.getcwd()}/exports/DEGs_UMAP_leiden/DEGs_{lab}_{method}_{org}_FSmethod-{FS_method}_seed-{seed}_var-{var_DEGs}.csv', \n",
    "            index=None)  \n",
    "        \n",
    "    df_populations.to_csv(f'{os.getcwd()}/exports/DEGs_UMAP_leiden/populations_{lab}_{method}_{org}_seed-{seed}.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ea341-fa4b-4308-a8e6-fb8a242e1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = ['ding', 'mereu']\n",
    "orgs = ['human', 'mouse']\n",
    "methods = ['10X', 'CELseq2', 'ddSEQ', 'Dropseq', 'inDrop', 'QUARTZseq', 'SingleNuclei', 'SMARTseq2',  'sci-RNA-seq', 'Seq-Well']\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "ray.init(ignore_reinit_error=True, num_cpus=8)\n",
    "done = ray.get([extract_DEGs_UMAP_leiden_adata.remote(lab=lab, org=org, method=method, seed=seed) \n",
    "                for lab, org, method, seed in list(product(*[labs, orgs, methods, seeds]))])\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03383771-a88f-439b-9258-a01a779ffb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab, org, method, seed = 'ding', 'human', '10X', 0\n",
    "\n",
    "FS_method = 'triku'\n",
    "\n",
    "adata = sc.read(f'{os.getcwd()}/data/{lab.capitalize()}_2020/{method}_{org}.h5ad')\n",
    "preprocessing(adata)\n",
    "\n",
    "df_populations = pd.read_csv(f'{os.getcwd()}/exports/DEGs_UMAP_leiden/populations_{lab}_{method}_{org}_seed-{seed}.csv', index_col=0)\n",
    "adata.obs['cell_names'] = adata.obs['cell_types']\n",
    "adata.obs[df_populations.columns] = df_populations.astype(str)\n",
    "\n",
    "dict_names, dict_pvals_adj, dict_scores = {}, {}, {}\n",
    "for FS_method in list_methods_all:\n",
    "    X_UMAP = np.loadtxt(f'{os.getcwd()}/exports/DEGs_UMAP_leiden/UMAP_{lab}_{method}_{org}_FSmethod-{FS_method}_seed-{seed}.txt') \n",
    "    adata.obsm[f'X_umap_{FS_method}'] = X_UMAP\n",
    "\n",
    "    dict_names[FS_method] = pd.read_csv(f'{os.getcwd()}/exports/DEGs_UMAP_leiden/DEGs_{lab}_{method}_{org}_FSmethod-{FS_method}_seed-{seed}_var-names.csv')\n",
    "    dict_pvals_adj[FS_method] = pd.read_csv(f'{os.getcwd()}/exports/DEGs_UMAP_leiden/DEGs_{lab}_{method}_{org}_FSmethod-{FS_method}_seed-{seed}_var-pvals_adj.csv')\n",
    "    dict_scores[FS_method] = pd.read_csv(f'{os.getcwd()}/exports/DEGs_UMAP_leiden/DEGs_{lab}_{method}_{org}_FSmethod-{FS_method}_seed-{seed}_var-scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26754b3e-98a7-42a7-b597-4ed3658c083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(list_methods_all) + 1, len(list_methods_all), figsize = (len(list_methods_all) * 3, (len(list_methods_all) + 1) * 3))\n",
    "\n",
    "for FS_method_idx, FS_method in enumerate(list_methods_all):\n",
    "    sc.pl.embedding(adata, basis=f'X_umap_{FS_method}', color='cell_types',legend_loc=False , ax=axs[0][FS_method_idx], show=False)\n",
    "\n",
    "for FS_method_idx_row, FS_method_row in enumerate(list_methods_all):\n",
    "    for FS_method_idx_col, FS_method_col in enumerate(list_methods_all):\n",
    "        sc.pl.embedding(adata, basis=f'X_umap_{FS_method_col}', color=FS_method_row, legend_loc=False, ax=axs[FS_method_idx_row + 1][FS_method_idx_col], show=False)\n",
    "        \n",
    "for idx_row in range(len(list_methods_all) + 1):\n",
    "    for idx_col in range(len(list_methods_all)):\n",
    "        axs[idx_row][idx_col].set_xlabel('')\n",
    "        axs[idx_row][idx_col].set_ylabel('')\n",
    "        axs[idx_row][idx_col].set_title('')\n",
    "\n",
    "for idx_row, row_name in enumerate(['cell_types'] + list_methods_all):\n",
    "    for idx_col, col_name in enumerate(list_methods_all):\n",
    "        axs[idx_row][idx_col].set_ylabel(row_name)\n",
    "        axs[idx_row][idx_col].set_title(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c34c8c-cadd-474c-9d13-8f02be097aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_names['scry']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f3edf-55a7-4196-a55c-a16a94099f76",
   "metadata": {},
   "source": [
    "## Analysis on continuous datasets\n",
    "\n",
    "To see if triku also works in datasets with continuous differentiation stages, we will use datasets from scvelo (pancreas dataset) and velocyto (dentate gyrus dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61100356-5c08-4f37-93c5-66d43776d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvelo as scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140668d4-01e7-4d31-b3d7-e7c477199cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = scv.datasets.pancreas()\n",
    "del adata.var\n",
    "del adata.obsm\n",
    "del adata.obsp\n",
    "\n",
    "scv.pp.filter_genes(adata, min_shared_counts=20)\n",
    "scv.pp.normalize_per_cell(adata)\n",
    "scv.pp.log1p(adata)\n",
    "\n",
    "scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "tk.tl.triku(adata)\n",
    "\n",
    "scv.tl.velocity(adata)\n",
    "scv.tl.velocity_graph(adata)\n",
    "\n",
    "scv.tl.umap(adata)\n",
    "scv.pl.velocity_embedding_stream(adata, basis='umap')\n",
    "\n",
    "scv.tl.paga(adata, groups='clusters')\n",
    "scv.pl.paga(adata, basis='umap', size=50, alpha=.1,\n",
    "            min_edge_width=2, node_size_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd9e4e-9228-45c6-acbe-085a65684c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvg = list(adata.var_names[adata.var['highly_variable']])\n",
    "\n",
    "for corr_val in [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]:\n",
    "    scv.tl.rank_velocity_genes(adata, groupby='clusters', min_corr=corr_val, n_genes=len(hvg))\n",
    "    df_names = scv.DataFrame(adata.uns['rank_velocity_genes']['names'])\n",
    "    df_scores = scv.DataFrame(adata.uns['rank_velocity_genes']['scores'])\n",
    "    \n",
    "    scvelo_genes = list(set(df_names.values.ravel()))\n",
    "    \n",
    "    print(len(scvelo_genes), len(hvg))\n",
    "    print(corr_val, len([i for i in scvelo_genes if i in hvg]) / len(scvelo_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec940fb7-a656-4674-8a3d-f7b121cd2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(f\"{os.getcwd()}/data/dentate_gyrus.loom\", backup_url=\"http://pklab.med.harvard.edu/velocyto/DentateGyrus/DentateGyrus.loom\")\n",
    "\n",
    "del adata.var\n",
    "del adata.obsm\n",
    "del adata.obsp\n",
    "\n",
    "scv.pp.filter_genes(adata, min_shared_counts=20)\n",
    "scv.pp.normalize_per_cell(adata)\n",
    "scv.pp.log1p(adata)\n",
    "\n",
    "scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "tk.tl.triku(adata)\n",
    "\n",
    "scv.tl.velocity(adata)\n",
    "scv.tl.velocity_graph(adata)\n",
    "\n",
    "scv.tl.umap(adata)\n",
    "scv.pl.velocity_embedding_stream(adata, basis='umap', color='ClusterName')\n",
    "\n",
    "scv.tl.paga(adata, groups='ClusterName')\n",
    "scv.pl.paga(adata, basis='umap', size=50, alpha=.1,\n",
    "            min_edge_width=2, node_size_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5472a-b3dc-4107-b0eb-cf8743d511a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvg = list(adata.var_names[adata.var['highly_variable']])\n",
    "\n",
    "for corr_val in [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]:\n",
    "    scv.tl.rank_velocity_genes(adata, groupby='ClusterName', min_corr=corr_val, n_genes=len(hvg))\n",
    "    df_names = scv.DataFrame(adata.uns['rank_velocity_genes']['names'])\n",
    "    df_scores = scv.DataFrame(adata.uns['rank_velocity_genes']['scores'])\n",
    "    \n",
    "    scvelo_genes = list(set(df_names.values.ravel()))\n",
    "    \n",
    "    print(len(scvelo_genes), len(hvg))\n",
    "    print(corr_val, len([i for i in scvelo_genes if i in hvg]) / len(scvelo_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbbc093-4b65-4fd2-b9a1-9dbea360523f",
   "metadata": {},
   "source": [
    "## Analysis of mean VS median correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68988a6d-97f6-4351-9d70-36603c19635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_median(adata):\n",
    "    n_windows = 70\n",
    "    n_HVG = adata.var['highly_variable'].sum()\n",
    "\n",
    "    X = np.log10(adata.X.toarray().mean(0))\n",
    "    Y_uncor = adata.var['triku_distance_uncorrected']\n",
    "\n",
    "    linspace = np.linspace(np.min(X), np.max(X), n_windows + 1)\n",
    "    linspace_median, linspace_mean = [], []\n",
    "    Y_median_arr = np.zeros(len(Y_uncor))\n",
    "    Y_mean_arr = np.zeros(len(Y_uncor))\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        mask = (X >= linspace[i]) & (X <= linspace[i + 1])\n",
    "        Y_median_arr[mask] = np.median(Y_uncor[mask])\n",
    "        Y_mean_arr[mask] = np.mean(Y_uncor[mask])\n",
    "        linspace_median.append(np.median(Y_uncor[mask])), linspace_mean.append(np.mean(Y_uncor[mask]))\n",
    "\n",
    "    Y_mean, Y_median = Y_uncor - Y_mean_arr, Y_uncor - Y_median_arr\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(25, 5))\n",
    "    X = np.log10(adata.X.toarray().mean(0))\n",
    "    Y_uncor, Y = adata.var['triku_distance_uncorrected'], adata.var['triku_distance']\n",
    "\n",
    "    max_y_mean = np.argsort(Y_mean)[-n_HVG:]\n",
    "    max_y_median = np.argsort(Y_median)[-n_HVG:]\n",
    "    max_both = np.intersect1d(max_y_mean, max_y_median)\n",
    "\n",
    "\n",
    "    plt.suptitle(f'Mean/median correction on {lab} {org}, {method}')\n",
    "    axs[0].set_title('Uncorrected')\n",
    "    axs[1].set_title('Mean correction')\n",
    "    axs[2].set_title('Median correction')\n",
    "    axs[3].set_title('Jaccard index of 0:i features')\n",
    "\n",
    "    axs[0].scatter(X, Y_uncor, c='#cbcbcb')\n",
    "    axs[0].scatter(X[max_y_mean], Y_uncor[max_y_mean], c='#ab0000')\n",
    "    axs[0].scatter(X[max_y_median], Y_uncor[max_y_median], c='#0000ab')\n",
    "    axs[0].scatter(X[max_both], Y_uncor[max_both], c='#676767')\n",
    "\n",
    "    axs[1].scatter(X, Y_mean, c='#cbcbcb')\n",
    "    axs[1].scatter(X[max_y_mean], Y_mean[max_y_mean], c='#ab0000')\n",
    "\n",
    "    axs[2].scatter(X, Y_median, c='#cbcbcb')\n",
    "    axs[2].scatter(X[max_y_median], Y_median[max_y_median], c='#0000ab')\n",
    "\n",
    "\n",
    "    axs[0].plot(linspace[:-1], linspace_mean, c=\"#ab0000\")\n",
    "    axs[0].plot(linspace[:-1], linspace_median, c=\"#0000ab\")\n",
    "    axs[1].plot(linspace[:-1], [0] * n_windows, c=\"#ab0000\")\n",
    "    axs[2].plot(linspace[:-1], [0] * n_windows, c=\"#0000ab\")\n",
    "\n",
    "    for idx in range(3):\n",
    "        axs[idx].set_xlabel('log$_{10}$ mean gene expression')\n",
    "        axs[idx].set_ylabel('Wasserstein distance')\n",
    "\n",
    "    axs[3].set_xlabel('Jaccard index')\n",
    "    axs[3].set_ylabel('# top features selected')    \n",
    "\n",
    "    jaccard_index_line = []\n",
    "    for idx in range(20, n_HVG, 5):\n",
    "        max_y_mean = np.argsort(Y_mean)[-idx:]\n",
    "        max_y_median = np.argsort(Y_median)[-idx:]\n",
    "        max_and = np.intersect1d(max_y_mean, max_y_median)\n",
    "        max_or = np.union1d(max_y_mean, max_y_median)\n",
    "\n",
    "        jaccard_index_line.append(len(max_and)/len(max_or))\n",
    "\n",
    "    axs[3].plot(np.arange(20, n_HVG, 5), jaccard_index_line)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3a5d3-2454-4fc1-8726-37f79a8d78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = ['ding', 'mereu']\n",
    "orgs = ['human', 'mouse']\n",
    "methods = ['10X', 'CELseq2', 'ddSEQ', 'Dropseq', 'inDrop', 'QUARTZseq', 'SingleNuclei', 'SMARTseq2',  'sci-RNA-seq', 'Seq-Well']\n",
    "\n",
    "for lab, org, method in list(product(*[labs, orgs, methods])): \n",
    "    if os.path.exists(f'{os.getcwd()}/data/{lab.capitalize()}_2020/{method}_{org}.h5ad'):\n",
    "        print(lab, org, method)\n",
    "        adata_x = sc.read(f'{os.getcwd()}/data/{lab.capitalize()}_2020/{method}_{org}.h5ad')\n",
    "        preprocessing(adata_x)\n",
    "        PCA_knn(adata_x, 0)\n",
    "        tk.tl.triku(adata_x, verbose='error', s=0)\n",
    "        \n",
    "        plot_mean_median(adata_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:triku-notebooks]",
   "language": "python",
   "name": "conda-env-triku-notebooks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
